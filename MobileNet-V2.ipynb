{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the directories containing your training and testing datasets\n",
    "train_dir = 'E:\\Python\\MobileNet-V2-Batik-Image-Classification\\dataset-v3[600]-5\\data-train'\n",
    "test_dir = 'E:\\Python\\MobileNet-V2-Batik-Image-Classification\\dataset-v3[600]-5\\data-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of classes in your dataset\n",
    "num_classes = 5\n",
    "\n",
    "# Set the input shape for MobileNetV2\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Set the number of trials for hyperparameter tuning\n",
    "num_trials = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image data generator with data augmentation for training data\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.4,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  brightness_range=[0.8, 1.2],\n",
    "                                  validation_split=0.2)\n",
    "\n",
    "#note: test data should not have to be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 435 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                                    target_size=input_shape[:2],\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='training',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "eval_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                                   target_size=input_shape[:2],\n",
    "                                                   class_mode='categorical',\n",
    "                                                   subset='validation',\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(directory=test_dir,\n",
    "                                                  target_size=input_shape[:2],\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune and their search spaces\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "\n",
    "    # Build the MobileNetV2 model\n",
    "    base_model = MobileNetV2(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Freeze the layers of the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate, decay=weight_decay),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train_generator,\n",
    "          steps_per_epoch=len(train_generator),\n",
    "          validation_data=eval_generator,\n",
    "          validation_steps=len(eval_generator),\n",
    "          epochs=25,\n",
    "          batch_size=batch_size,\n",
    "          verbose=1)\n",
    "\n",
    "    # Evaluate the model on the evaluation generator\n",
    "    _, accuracy = model.evaluate(eval_generator, steps=len(eval_generator), verbose=0)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-16 00:19:08,098] A new study created in memory with name: no-name-bfdccb6d-0b16-4e68-84a5-3389bacbb608\n",
      "C:\\Users\\Zia\\AppData\\Local\\Temp\\ipykernel_7724\\2460344492.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "C:\\Users\\Zia\\AppData\\Local\\Temp\\ipykernel_7724\\2460344492.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14/14 [==============================] - 42s 3s/step - loss: 2.7688 - accuracy: 0.5034 - val_loss: 0.6555 - val_accuracy: 0.7810\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.4836 - accuracy: 0.8000 - val_loss: 0.3417 - val_accuracy: 0.8762\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.3988 - accuracy: 0.8598 - val_loss: 0.3931 - val_accuracy: 0.8667\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.3101 - accuracy: 0.8966 - val_loss: 0.3125 - val_accuracy: 0.8857\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.1881 - accuracy: 0.9448 - val_loss: 0.2938 - val_accuracy: 0.8857\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1467 - accuracy: 0.9517 - val_loss: 0.2340 - val_accuracy: 0.9333\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 35s 3s/step - loss: 0.1510 - accuracy: 0.9494 - val_loss: 0.1874 - val_accuracy: 0.9238\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.1459 - accuracy: 0.9448 - val_loss: 0.2244 - val_accuracy: 0.9333\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 35s 3s/step - loss: 0.1797 - accuracy: 0.9379 - val_loss: 0.3213 - val_accuracy: 0.8571\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.1690 - accuracy: 0.9471 - val_loss: 0.2325 - val_accuracy: 0.9333\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1307 - accuracy: 0.9540 - val_loss: 0.2054 - val_accuracy: 0.9143\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1746 - accuracy: 0.9494 - val_loss: 0.3031 - val_accuracy: 0.9048\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.1267 - accuracy: 0.9540 - val_loss: 0.3007 - val_accuracy: 0.9238\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1399 - accuracy: 0.9471 - val_loss: 0.1991 - val_accuracy: 0.9333\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1029 - accuracy: 0.9701 - val_loss: 0.2756 - val_accuracy: 0.8952\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0802 - accuracy: 0.9793 - val_loss: 0.1078 - val_accuracy: 0.9429\n",
      "Epoch 17/25\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.0670 - accuracy: 0.9678 - val_loss: 0.3329 - val_accuracy: 0.8857\n",
      "Epoch 18/25\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1342 - accuracy: 0.9494 - val_loss: 0.1197 - val_accuracy: 0.9619\n",
      "Epoch 19/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.1270 - accuracy: 0.9448 - val_loss: 0.1057 - val_accuracy: 0.9619\n",
      "Epoch 20/25\n",
      "14/14 [==============================] - 34s 2s/step - loss: 0.0914 - accuracy: 0.9724 - val_loss: 0.2762 - val_accuracy: 0.9333\n",
      "Epoch 21/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.0635 - accuracy: 0.9770 - val_loss: 0.2626 - val_accuracy: 0.9238\n",
      "Epoch 22/25\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0826 - accuracy: 0.9701 - val_loss: 0.2991 - val_accuracy: 0.9048\n",
      "Epoch 23/25\n",
      "14/14 [==============================] - 28s 2s/step - loss: 0.0894 - accuracy: 0.9793 - val_loss: 0.3958 - val_accuracy: 0.8762\n",
      "Epoch 24/25\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1269 - accuracy: 0.9494 - val_loss: 0.2565 - val_accuracy: 0.9143\n",
      "Epoch 25/25\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.0788 - accuracy: 0.9793 - val_loss: 0.1785 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-16 00:32:54,185] Trial 0 finished with value: 0.9142857193946838 and parameters: {'learning_rate': 0.004727242931492625, 'batch_size': 32, 'weight_decay': 1.1969071273930583e-05}. Best is trial 0 with value: 0.9142857193946838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "14/14 [==============================] - 36s 2s/step - loss: 1.0594 - accuracy: 0.5954 - val_loss: 0.4923 - val_accuracy: 0.8286\n",
      "Epoch 2/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.4589 - accuracy: 0.8414 - val_loss: 0.3573 - val_accuracy: 0.8762\n",
      "Epoch 3/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.3720 - accuracy: 0.8552 - val_loss: 0.2779 - val_accuracy: 0.8952\n",
      "Epoch 4/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.2951 - accuracy: 0.8736 - val_loss: 0.1720 - val_accuracy: 0.9429\n",
      "Epoch 5/25\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.2626 - accuracy: 0.8989 - val_loss: 0.2320 - val_accuracy: 0.9048\n",
      "Epoch 6/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.1979 - accuracy: 0.9356 - val_loss: 0.2605 - val_accuracy: 0.9238\n",
      "Epoch 7/25\n",
      "14/14 [==============================] - 33s 2s/step - loss: 0.1721 - accuracy: 0.9563 - val_loss: 0.2309 - val_accuracy: 0.9333\n",
      "Epoch 8/25\n",
      "14/14 [==============================] - 31s 2s/step - loss: 0.1484 - accuracy: 0.9425 - val_loss: 0.1723 - val_accuracy: 0.9238\n",
      "Epoch 9/25\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1023 - accuracy: 0.9655 - val_loss: 0.1757 - val_accuracy: 0.9429\n",
      "Epoch 10/25\n",
      "14/14 [==============================] - 30s 2s/step - loss: 0.1289 - accuracy: 0.9586 - val_loss: 0.2449 - val_accuracy: 0.9238\n",
      "Epoch 11/25\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.1274 - accuracy: 0.9540 - val_loss: 0.3364 - val_accuracy: 0.8667\n",
      "Epoch 12/25\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.1205 - accuracy: 0.9586 - val_loss: 0.1557 - val_accuracy: 0.9429\n",
      "Epoch 13/25\n",
      "14/14 [==============================] - 35s 2s/step - loss: 0.1464 - accuracy: 0.9609 - val_loss: 0.1695 - val_accuracy: 0.9333\n",
      "Epoch 14/25\n",
      "14/14 [==============================] - 36s 3s/step - loss: 0.1336 - accuracy: 0.9494 - val_loss: 0.1946 - val_accuracy: 0.9238\n",
      "Epoch 15/25\n",
      "14/14 [==============================] - 32s 2s/step - loss: 0.1103 - accuracy: 0.9609 - val_loss: 0.2359 - val_accuracy: 0.8952\n",
      "Epoch 16/25\n",
      "14/14 [==============================] - 43s 3s/step - loss: 0.0935 - accuracy: 0.9678 - val_loss: 0.1805 - val_accuracy: 0.9238\n",
      "Epoch 17/25\n",
      " 7/14 [==============>...............] - ETA: 18s - loss: 0.1004 - accuracy: 0.9643"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters from the study\n",
    "best_params = study.best_params\n",
    "best_val_accuracy = study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild the model with the best hyperparameters\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "best_batch_size = best_params['batch_size']\n",
    "best_weight_decay = best_params['weight_decay']\n",
    "# best_dropout_rate = best_params['dropout_rate']\n",
    "\n",
    "print(f\"best_learning_rate : {best_learning_rate} \")\n",
    "print(f\"best_batch_size : {best_batch_size} \")\n",
    "print(f\"best_weight_decay : {best_weight_decay} \")\n",
    "print(f\"best_val_accuracy : {best_val_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
